{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "\n",
    "PROJECT_ROOT = os.path.join(os.getcwd(), '..')\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT,'data')\n",
    "MODEL_PATH = os.path.join(PROJECT_ROOT,'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(merge, X_pred):\n",
    "    X = merge.drop(['click_time', 'attributed_time', 'is_attributed'], axis=1).values\n",
    "    y = merge['is_attributed'].values\n",
    "    categorical_features = ['ip','app','os','channel','device', 'day']\n",
    "    predictors = list(set(merge.columns) - set(['attributed_time', 'click_time', 'is_attributed']))\n",
    "\n",
    "    lgbtrain = lgb.Dataset(X, label=y,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'metric':'auc',     \n",
    "\n",
    "        'learning_rate': 0.15,\n",
    "        'num_leaves': 7,  # 2^max_depth - 1\n",
    "        'max_depth': 3,  # -1 means no limit\n",
    "        'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        # 'scale_pos_weight':99\n",
    "    }\n",
    "\n",
    "    evals_results = {}\n",
    "    num_boost_round = 250\n",
    "    early_stopping_rounds = 30\n",
    "\n",
    "    booster = lgb.train(\n",
    "         lgb_params, \n",
    "         lgbtrain, \n",
    "         valid_sets=[lgbtrain], \n",
    "         valid_names=['train'], \n",
    "         evals_result=evals_results, \n",
    "         num_boost_round=num_boost_round,\n",
    "         early_stopping_rounds=early_stopping_rounds,\n",
    "         verbose_eval=1\n",
    "    )\n",
    "    \n",
    "    # predict test data\n",
    "    y_prob = booster.predict(X_pred)\n",
    "    return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['day'] = df.click_time.dt.day\n",
    "    df['hour'] = df.click_time.dt.hour\n",
    "    df['minute'] = df.click_time.dt.minute\n",
    "    df['second'] = df.click_time.dt.second\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now():\n",
    "    now = datetime.datetime.now()\n",
    "    return '{0:%Y-%m-%d %H:%M:%S}'.format(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(booster):\n",
    "    \n",
    "    reader = pd.read_csv(os.path.join(DATA_DIR,'test.csv'), parse_dates=['click_time'], chunksize=100000)\n",
    "    for i, test in enumerate(reader):\n",
    "        print('[{}]Start:Preprocessing Data:Size:{}'.format(get_now(), len(test)))\n",
    "        test = preprocess(test)\n",
    "        print('[{}]Finish:Preprocessing Data:Size:{}'.format(get_now(), len(test)))\n",
    "        \n",
    "        print('[{}]Start:Predicting Data'.format(get_now()))\n",
    "        X = test.drop(['click_id','click_time'], axis=1)\n",
    "        y_prob = booster.predict(X.values)\n",
    "        #y_class_one = [i[1] for i in y_prob]\n",
    "        print('[{}]Finish:Predicting Data'.format(get_now()))\n",
    "       \n",
    "        print('[{}]Start:output Data'.format(get_now()))\n",
    "        y = pd.DataFrame({\n",
    "                                        'click_id' : test['click_id'],\n",
    "                                        'is_attributed' : y_prob\n",
    "                                        })\n",
    "        \n",
    "        output = os.path.join(DATA_DIR, 'submission_lgb.csv')\n",
    "        if i == 0:\n",
    "            if os.path.isfile(output):\n",
    "                os.remove(output)\n",
    "            header = True\n",
    "        else:\n",
    "            header = False\n",
    "        y.to_csv(output, index=False, header=header, mode='a')\n",
    "        print('[{}]Finish:output Data'.format(get_now()))\n",
    "    \n",
    "    print('[{}]Finish:All Process'.format(get_now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-04-24 01:31:48]Start:read positive\n",
      "[2018-04-24 01:31:49]Start:read negative\n"
     ]
    }
   ],
   "source": [
    "print('[{}]Start:read positive'.format(get_now()))\n",
    "positive = pd.read_csv(os.path.join(DATA_DIR, 'train_positive.csv'), parse_dates=['click_time'])\n",
    "print('[{}]Start:read negative'.format(get_now()))\n",
    "negative = pd.read_csv(os.path.join(DATA_DIR, 'train_negative.csv'), parse_dates=['click_time'])\n",
    "print('[{}]Start:read test'.format(get_now()))\n",
    "test = pd.read_csv(os.path.join(DATA_DIR,'test.csv'), parse_dates=['click_time'])\n",
    "test = preprocess(test)\n",
    "X = test.drop(['click_id','click_time'], axis=1)\n",
    "click_id = test['click_id']\n",
    "del test\n",
    "gc.collect()\n",
    "X_pred = X.values\n",
    "\n",
    "print('[{}]Finished:All data preparing'.format(get_now()))\n",
    "\n",
    "y_probs = []\n",
    "for i in range(200):\n",
    "    print('[{}]Start: process:{}'.format(get_now(), i))\n",
    "    negative_sampled = negative.sample(500000)\n",
    "    merge = pd.concat([positive, negative_sampled])\n",
    "    merge = preprocess(merge)\n",
    "    print('[{}]Start: process:{}:training'.format(get_now(), i))\n",
    "    y_probs.append(train_and_predict(merge, X_pred))\n",
    "    print('[{}]Finished: process:{}:training'.format(get_now(), i))\n",
    "\n",
    "del negative\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
